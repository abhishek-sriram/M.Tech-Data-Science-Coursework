{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76dca5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\prath\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\prath\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('am', 'VBP'), ('learning', 'VBG'), ('NLP', 'NNP'), ('in', 'IN'), ('Python', 'NNP')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "sentence = \"I am learning NLP in Python\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd04484",
   "metadata": {},
   "source": [
    "punkt module is a sentence tokenizer. It divides a lengthy sentence into tokens using unsupervised algorithm\n",
    "\n",
    "averaged_perceptron_tagger: This zip file has predefined english PoS (Parts of Speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeddf311",
   "metadata": {},
   "source": [
    "# Example - BoW implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a007e1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazing' 'an' 'best' 'game' 'great' 'is' 'of' 'series' 'so' 'the'\n",
      " 'thrones' 'tv']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import re\n",
    "\n",
    "doc1 = 'Game of Thrones is an amazing tv series!'\n",
    "doc2 = 'Game of Thrones is the best tv series!'\n",
    "doc3 = 'Game of Thrones is so great'\n",
    "\n",
    "l_doc1 = re.sub(r\"[^a-zA-Z0-9]\", \" \", doc1.lower()).split()\n",
    "l_doc2 = re.sub(r\"[^a-zA-Z0-9]\", \" \", doc2.lower()).split()\n",
    "l_doc3 = re.sub(r\"[^a-zA-Z0-9]\", \" \", doc3.lower()).split()\n",
    "\n",
    "wordset12 = np.union1d(l_doc1,l_doc2)\n",
    "wordset =  np.union1d(wordset12,l_doc3)\n",
    "print(wordset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f3fcc",
   "metadata": {},
   "source": [
    "<B>Displays the list of tuples where each tuple contains a token and its POS tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbf934f",
   "metadata": {},
   "source": [
    "<B> Computes the union of words from the first two documents, ensuring no duplicates and creating a combined word set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cea2c0e",
   "metadata": {},
   "source": [
    "<B>Function to create a dictionary of word frequencies:\n",
    "dict.fromkeys(wordset, 0): Initializes a dictionary with wordset keys and zero values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0314874",
   "metadata": {},
   "source": [
    "<B>Creates a DataFrame where each row corresponds to a document, and columns represent word counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44618db",
   "metadata": {},
   "source": [
    "<B>Displays the first few rows of the DataFrame, showing the word counts for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00b9bca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>an</th>\n",
       "      <th>best</th>\n",
       "      <th>game</th>\n",
       "      <th>great</th>\n",
       "      <th>is</th>\n",
       "      <th>of</th>\n",
       "      <th>series</th>\n",
       "      <th>so</th>\n",
       "      <th>the</th>\n",
       "      <th>thrones</th>\n",
       "      <th>tv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amazing  an  best  game  great  is  of  series  so  the  thrones  tv\n",
       "0        1   1     0     1      0   1   1       1   0    0        1   1\n",
       "1        0   0     1     1      0   1   1       1   0    1        1   1\n",
       "2        0   0     0     1      1   1   1       0   1    0        1   0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculateBOW(wordset,l_doc):\n",
    "  tf_diz = dict.fromkeys(wordset,0)\n",
    "  for word in l_doc:\n",
    "      tf_diz[word]=l_doc.count(word)\n",
    "  return tf_diz\n",
    "bow1 = calculateBOW(wordset,l_doc1)\n",
    "bow2 = calculateBOW(wordset,l_doc2)\n",
    "bow3 = calculateBOW(wordset,l_doc3)\n",
    "df_bow = pd.DataFrame([bow1,bow2,bow3])\n",
    "df_bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d17b446",
   "metadata": {},
   "source": [
    "# Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d58197",
   "metadata": {},
   "source": [
    "<B>A list of strings where each string represents a document or a sentence. These documents describe various cities in India and their notable features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2b8cc7",
   "metadata": {},
   "source": [
    "<B> Initializes the CountVectorizer object. This tool converts text data into a matrix of token counts (i.e., a Bag of Words model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0853b406",
   "metadata": {},
   "source": [
    "<B>Prints the sparse matrix representation of the word counts. This matrix is in a sparse format to save memory, especially when dealing with large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e67e450",
   "metadata": {},
   "source": [
    "<B>Converts the sparse matrix to a dense array and prints it. Each row corresponds to a document, and each column corresponds to a unique word in the vocabulary. The values are the counts of each word in the respective document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a0a48a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 14)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 26)\t1\n",
      "  (1, 13)\t1\n",
      "  (1, 18)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 3)\t1\n",
      "  (2, 13)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 7)\t1\n",
      "  (3, 14)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 25)\t1\n",
      "  (4, 13)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 24)\t1\n",
      "  (4, 12)\t1\n",
      "  (4, 22)\t1\n",
      "  (5, 26)\t1\n",
      "  (5, 18)\t1\n",
      "  (5, 12)\t1\n",
      "  (5, 6)\t1\n",
      "  :\t:\n",
      "  (6, 14)\t1\n",
      "  (6, 27)\t1\n",
      "  (6, 16)\t1\n",
      "  (7, 13)\t1\n",
      "  (7, 7)\t1\n",
      "  (7, 11)\t1\n",
      "  (8, 13)\t1\n",
      "  (8, 26)\t1\n",
      "  (8, 18)\t1\n",
      "  (8, 11)\t1\n",
      "  (8, 28)\t1\n",
      "  (8, 2)\t1\n",
      "  (9, 13)\t1\n",
      "  (9, 7)\t1\n",
      "  (9, 21)\t1\n",
      "  (9, 10)\t1\n",
      "  (10, 14)\t1\n",
      "  (10, 13)\t1\n",
      "  (10, 17)\t1\n",
      "  (10, 20)\t1\n",
      "  (11, 13)\t1\n",
      "  (11, 7)\t1\n",
      "  (11, 17)\t2\n",
      "  (11, 15)\t1\n",
      "  (11, 19)\t1\n",
      "[[0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 2 0 1 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "text=[\"kolkata big city india trade\",\"mumbai financial capital india\",\"delhi capital india\",\"kolkata capital colonial times\",\n",
    "     \"bangalore tech hub india software\",\"mumbai hub trade commerce stock exchange\",\"kolkata victoria memorial\",\"delhi india gate\",\n",
    "      \"mumbai gate way india trade business\",\"delhi red fort india\",\"kolkata metro oldest india\",\n",
    "      \"delhi metro largest metro network india\"]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#using the count vectorizer\n",
    "count = CountVectorizer()\n",
    "word_count=count.fit_transform(text)\n",
    "print(word_count)\n",
    "word_count.shape\n",
    "print(word_count.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda00542",
   "metadata": {},
   "source": [
    "<B> INFERENCE :    The code demonstrates a basic implementation of the Bag of Words model, a popular text representation technique used in NLP. It converts textual documents into numerical vectors based on word frequencies.\n",
    "The resulting DataFrame provides a structured view of word occurrences across documents, which is useful for further text analysis, such as text classification, clustering, or information retrieval.\n",
    "For more sophisticated text processing tasks, consider using libraries like scikit-learn for optimized BoW implementations and additional features such as TF-IDF (Term Frequency-Inverse Document Frequency) scaling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
