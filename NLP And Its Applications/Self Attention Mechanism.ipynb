{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f3e760d-326f-4d97-bbef-ada98be3433c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: [0.8 0.6 0.5]\n",
      "K1: [0.6 0.5 0.4]\n",
      "V1: [0.6 0.5 0.4]\n",
      "Scaled Attention Scores: [0.56580326 1.0623245  0.58312377]\n",
      "Softmax Scores: [0.27318918 0.44884865 0.27796217]\n",
      "Weighted Sum (Before Residual): [0.66197351 0.75222054 0.78687514]\n",
      "Residual Output: [1.26197351 1.25222054 1.18687514]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the query, key, value weight matrices (Q_w, K_w, V_w)\n",
    "Q_w = np.array([[0.5, 0.1, 0.3],\n",
    "                [0.2, 0.3, 0.1],\n",
    "                [0.1, 0.2, 0.5],\n",
    "                [0.3, 0.5, 0.2]])\n",
    "\n",
    "K_w = np.array([[0.4, 0.2, 0.3],\n",
    "                [0.1, 0.4, 0.2],\n",
    "                [0.3, 0.1, 0.4],\n",
    "                [0.2, 0.3, 0.1]])\n",
    "\n",
    "V_w = np.array([[0.2, 0.4, 0.1],\n",
    "                [0.3, 0.2, 0.4],\n",
    "                [0.1, 0.3, 0.2],\n",
    "                [0.4, 0.1, 0.3]])\n",
    "\n",
    "# Define the word inputs (e.g., 3 words)\n",
    "words = np.array([\n",
    "    [1, 0, 0, 1],  # Word 1\n",
    "    [0, 2, 2, 0],  # Word 2\n",
    "    [1, 1, 0, 0]   # Word 3\n",
    "])\n",
    "\n",
    "# Function to compute queries, keys, and values\n",
    "def compute_qkv(word, Q_w, K_w, V_w):\n",
    "    Q = np.dot(word, Q_w)\n",
    "    K = np.dot(word, K_w)\n",
    "    V = np.dot(word, V_w)\n",
    "    return Q, K, V\n",
    "\n",
    "# Compute Q, K, V for each word\n",
    "Q1, K1, V1 = compute_qkv(words[0], Q_w, K_w, V_w)  # For word 1\n",
    "Q2, K2, V2 = compute_qkv(words[1], Q_w, K_w, V_w)  # For word 2\n",
    "Q3, K3, V3 = compute_qkv(words[2], Q_w, K_w, V_w)  # For word 3\n",
    "\n",
    "# Function to calculate scaled attention score (dot product between Q and K)\n",
    "def scaled_attention_score(Q, K, dim):\n",
    "    score = np.dot(Q, K.T) / np.sqrt(dim)  # Scale by sqrt of the dimension (dimensionality scaling)\n",
    "    return score\n",
    "\n",
    "# Dimensionality (size of the query/key vectors)\n",
    "dim = Q1.shape[0]  # Dimension size (in this case it's 3)\n",
    "\n",
    "# Compute scaled attention scores between Q1 and K1, K2, K3\n",
    "scores = np.array([\n",
    "    scaled_attention_score(Q1, K1, dim),\n",
    "    scaled_attention_score(Q1, K2, dim),\n",
    "    scaled_attention_score(Q1, K3, dim)\n",
    "])\n",
    "\n",
    "# Apply softmax to the attention scores\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))  # For numerical stability\n",
    "    return e_x / np.sum(e_x)\n",
    "\n",
    "softmax_scores = softmax(scores)\n",
    "\n",
    "# Calculate the weighted sum of values (V1, V2, V3) using the softmax scores\n",
    "weighted_sum = softmax_scores[0] * V1 + softmax_scores[1] * V2 + softmax_scores[2] * V3\n",
    "\n",
    "# Add a simple residual connection (output = weighted sum + input, e.g., word1 as input here)\n",
    "residual_output = weighted_sum + np.dot(words[0], V_w)\n",
    "\n",
    "# Print results\n",
    "print(f\"Q1: {Q1}\")\n",
    "print(f\"K1: {K1}\")\n",
    "print(f\"V1: {V1}\")\n",
    "print(f\"Scaled Attention Scores: {scores}\")\n",
    "print(f\"Softmax Scores: {softmax_scores}\")\n",
    "print(f\"Weighted Sum (Before Residual): {weighted_sum}\")\n",
    "print(f\"Residual Output: {residual_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b67cb0-9b58-49c9-93dc-38780d77fc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
